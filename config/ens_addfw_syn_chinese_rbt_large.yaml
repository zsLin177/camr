frameworks:
- ["amr", "zho"]

encoder: /data/slzhou/PLMs/chinese-roberta-wwm-ext-large
accumulation_steps: 1
batch_size: 8
query_length: 3
use_syn: true
decoder_learning_rate: 1.5e-4
add_fw: true
base_model: /data/slzhou/S2TCAMR_1/S2TCAMR/outputs/train_catdev_lstm_syn_addfw_s123_lr2.0/best_checkpoint.h5