accumulation_steps: 2
activation: relu
balance_loss_weights: true
batch_size: 8
beta_2: 0.98
blank_weight: 1.0
char_embedding: true
char_embedding_size: 128
config: config/base_amr.yaml
data_directory: ccl2022
decoder_delay_steps: 0
decoder_learning_rate: 0.0006
decoder_weight_decay: 1.2e-06
dist_backend: nccl
dist_url: localhost
distributed: false
dropout_anchor: 0.5
dropout_edge_attribute: 0.5
dropout_edge_label: 0.5
dropout_edge_presence: 0.5
dropout_label: 0.5
dropout_property: 0.7
dropout_top: 0.9
dropout_transformer: 0.1
dropout_transformer_attention: 0.1
dropout_word: 0.1
encoder: xlm-roberta-base
encoder_delay_steps: 2000
encoder_freeze_embedding: true
encoder_learning_rate: 6.0e-05
encoder_weight_decay: 0.01
epochs: 100
focal: true
grad_norm_alpha: 1.5
grad_norm_lr: 0.001
group_ops: false
hidden_size: 768
hidden_size_anchor: 128
hidden_size_edge_attribute: 128
hidden_size_edge_label: 256
hidden_size_edge_presence: 512
hidden_size_ff: 3072
label_smoothing: 0.1
layerwise_lr_decay: 1.0
log_wandb: true
n_attention_heads: 8
n_encoder_layers: 12
n_layers: 3
n_mixture_components: 15
name: default
normalize: true
pre_norm: true
query_length: 3
save_checkpoints: true
wandb_log_mode: null
warmup_steps: 6000
workers: 1
